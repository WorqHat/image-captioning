<h1 align="center">Image Captioning using Deep-Learning</h1>
<h4 align="center">Security Maintenance Application for User Organization SLA Protocols</h4>

<p align="center">
  <img alt="License" src="https://img.shields.io/github/license/worqhat/image-captioning?style=flat-square" />
  <img alt="GitHub contributors" src="https://img.shields.io/github/contributors/worqhat/image-captioning?style=flat-square" />
</p>

## Introduction
This assignment aims to describe the content of an image by using CNNs and RNNs to build an Image Caption Generator. The model would be based on the paper [[4]](https://arxiv.org/pdf/1411.4555.pdf) and it will be implemented using Tensorflow and Keras. The dataset used is [Flickr 8K](https://www.kaggle.com/adityajn105/flickr8k), consisting of 8,000 images each one paired with five different captions to provide clear descriptions. We can also use the Flickr30K dataset for a production based use case.

The implementation has been done using Python in a Jupyter notebook, where every step is carefully documented.

## Further work
Despite the good results on the previous example, the Bilingual Evaluation Understudy (BLEU) Score for n-grams where n is greater than 2 is not very positive. As future work it would be interesting
to study changes in the architecture from where to input the picture.

## Copyrighted By
This Application belongs solely under the Propreitorship of WorqHat (Winlysis Private Limited) and its respective owners.
